{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "508d1348",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching ABIDE data: 100%|██████████| 48/48 [23:52<00:00, 29.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available pipelines: [('cpac', True, True, 'rois_aal'), ('cpac', True, True, 'rois_cc200'), ('cpac', True, True, 'rois_dosenbach160'), ('cpac', True, False, 'rois_aal'), ('cpac', True, False, 'rois_cc200'), ('cpac', True, False, 'rois_dosenbach160'), ('cpac', False, True, 'rois_aal'), ('cpac', False, True, 'rois_cc200'), ('cpac', False, True, 'rois_dosenbach160'), ('cpac', False, False, 'rois_aal'), ('cpac', False, False, 'rois_cc200'), ('cpac', False, False, 'rois_dosenbach160'), ('ccs', True, True, 'rois_aal'), ('ccs', True, True, 'rois_cc200'), ('ccs', True, True, 'rois_dosenbach160'), ('ccs', True, False, 'rois_aal'), ('ccs', True, False, 'rois_cc200'), ('ccs', True, False, 'rois_dosenbach160'), ('ccs', False, True, 'rois_aal'), ('ccs', False, True, 'rois_cc200'), ('ccs', False, True, 'rois_dosenbach160'), ('ccs', False, False, 'rois_aal'), ('ccs', False, False, 'rois_cc200'), ('ccs', False, False, 'rois_dosenbach160'), ('dparsf', True, True, 'rois_aal'), ('dparsf', True, True, 'rois_cc200'), ('dparsf', True, True, 'rois_dosenbach160'), ('dparsf', True, False, 'rois_aal'), ('dparsf', True, False, 'rois_cc200'), ('dparsf', True, False, 'rois_dosenbach160'), ('dparsf', False, True, 'rois_aal'), ('dparsf', False, True, 'rois_cc200'), ('dparsf', False, True, 'rois_dosenbach160'), ('dparsf', False, False, 'rois_aal'), ('dparsf', False, False, 'rois_cc200'), ('dparsf', False, False, 'rois_dosenbach160'), ('niak', True, True, 'rois_aal'), ('niak', True, True, 'rois_cc200'), ('niak', True, True, 'rois_dosenbach160'), ('niak', True, False, 'rois_aal'), ('niak', True, False, 'rois_cc200'), ('niak', True, False, 'rois_dosenbach160'), ('niak', False, True, 'rois_aal'), ('niak', False, True, 'rois_cc200'), ('niak', False, True, 'rois_dosenbach160'), ('niak', False, False, 'rois_aal'), ('niak', False, False, 'rois_cc200'), ('niak', False, False, 'rois_dosenbach160')]\n",
      "Number of subjects:  20\n",
      "Class distribution:  DX_GROUP\n",
      "1    10\n",
      "2    10\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Data Download\n",
    "from tqdm import tqdm\n",
    "from itertools import product\n",
    "from nilearn import datasets\n",
    "\n",
    "pipelines = [\"cpac\", \"ccs\", \"dparsf\", \"niak\"]\n",
    "band_pass = [True, False]\n",
    "global_signal = [True, False]\n",
    "parcellations = [\"rois_aal\", \"rois_cc200\", \"rois_dosenbach160\"]\n",
    "\n",
    "# Subset of subjects to download\n",
    "SUB_IDS = [50012, 50014, 50015, 50016, 50020, 50022, 50023, 50024, 50025, 50027, # controls\n",
    "           50030, 50031, 50032, 50033, 50034, 50035, 50036, 50037, 50038, 50040] # autism\n",
    "\n",
    "def fetch_data(pipe, bp, gsr, parc):\n",
    "    bunch = datasets.fetch_abide_pcp(SUB_ID=SUB_IDS, data_dir=\"./abide_data\", verbose=0,\n",
    "                                     pipeline=pipe, derivatives=parc, band_pass_filtering=bp, global_signal_regression=gsr)\n",
    "    return (pipe, bp, gsr, parc), bunch\n",
    "\n",
    "all_combinations = list(product(pipelines, band_pass, global_signal, parcellations))\n",
    "abide_dataset = {}\n",
    "\n",
    "for combo in tqdm(all_combinations, desc=\"Fetching ABIDE data\"):\n",
    "    key, bunch = fetch_data(*combo)\n",
    "    abide_dataset[key] = bunch\n",
    "\n",
    "print(f\"Available pipelines: {list(abide_dataset.keys())}\")\n",
    "print(f\"Number of subjects:  {len(abide_dataset[('cpac', True, True, 'rois_aal')].phenotypic)}\")\n",
    "print(f\"Class distribution:  {abide_dataset[('cpac', True, True, 'rois_aal')].phenotypic['DX_GROUP'].value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5dd92f4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\.conda\\envs\\psy126\\Lib\\site-packages\\tqdm_joblib\\__init__.py:4: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting multiverse analysis for all universes...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b9604d9424f482694322299385ce2a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Performing multiverse analysis::   0%|          | 0/192 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The multiverse analysis completed without any errors.\n"
     ]
    }
   ],
   "source": [
    "from comet import multiverse\n",
    "\n",
    "forking_paths = {\n",
    "    \"pipeline\": [\"cpac\", \"ccs\", \"dparsf\", \"niak\"],                          # Preprocessing pipelines\n",
    "    \"parcellation\": [\"rois_aal\", \"rois_cc200\", \"rois_dosenbach160\"],        # Parcellated time series data\n",
    "    \"band_pass\": [True, False],                                             # Band-pass filtering\n",
    "    \"global_signal\": [True, False],                                         # Global signal regression\n",
    "    \"connectivity\":[                                                        # Functional connectivity method\n",
    "        {\"name\": \"pearson\", \"func\": \"comet.connectivity.Static_Pearson(ts).estimate()\"},\n",
    "        {\"name\": \"partial\", \"func\": \"comet.connectivity.Static_Partial(ts).estimate()\"}],\n",
    "    \"regularisation\": [0.25, 1.0]                                           # Regularisation strength for the classifier\n",
    "}\n",
    "\n",
    "def analysis_template():\n",
    "    import comet\n",
    "    import numpy as np\n",
    "    from nilearn import datasets\n",
    "    from sklearn.pipeline import Pipeline\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "\n",
    "    # Subset of subjects do use\n",
    "    SUB_IDS = [50012, 50014, 50015, 50016, 50020, 50022, 50023, 50024, 50025, 50027, # controls\n",
    "               50030, 50031, 50032, 50033, 50034, 50035, 50036, 50037, 50038, 50040] # autism\n",
    "\n",
    "    # Get data (if available, it will be loaded from disk)\n",
    "    data = datasets.fetch_abide_pcp(SUB_ID=SUB_IDS, data_dir=\"./abide_data\", verbose=0,\n",
    "                                    pipeline={{pipeline}},\n",
    "                                    derivatives={{parcellation}},\n",
    "                                    band_pass_filtering={{band_pass}},\n",
    "                                    global_signal_regression={{global_signal}})\n",
    "\n",
    "    time_series = data[{{parcellation}}]\n",
    "    diagnosis = data[\"phenotypic\"][\"DX_GROUP\"]\n",
    "\n",
    "    # Calculate FC\n",
    "    tri_ix = None\n",
    "    features = []\n",
    "\n",
    "    for ts in time_series:\n",
    "        FC = {{connectivity}}\n",
    "\n",
    "        if tri_ix == None:\n",
    "            tri_ix = np.triu_indices_from(FC, k=1)\n",
    "\n",
    "        feat_vec = FC[tri_ix]\n",
    "        features.append(feat_vec)\n",
    "\n",
    "    # Prepare features (FC estimates) and target (autism/control)\n",
    "    X = np.vstack(features)\n",
    "    X[np.isnan(X)] = 0.0\n",
    "    y = np.array(diagnosis)\n",
    "\n",
    "    # Classification model\n",
    "    model = Pipeline([('scaler', StandardScaler()), ('reg', LogisticRegression(penalty='l2', C={{regularisation}}, tol=1e-3))])\n",
    "    cv = StratifiedKFold(n_splits=5)\n",
    "    accuracies = cross_val_score(model, X, y, cv=cv, scoring='accuracy')\n",
    "\n",
    "    # Save the results\n",
    "    comet.utils.save_universe_results({\"accuracy\": accuracies})\n",
    "\n",
    "# Create and run the multiverse analysis\n",
    "mverse = multiverse.Multiverse(name=\"example_mv_abide\")\n",
    "mverse.create(analysis_template, forking_paths)\n",
    "mverse.run(parallel=8)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "psy126",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
